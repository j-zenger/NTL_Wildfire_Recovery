---
title: "Palisades_Data_Cleaning"
author: "Josie Zenger"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r Packages}
# Load packages
library(blackmarbler)
library(geodata)
library(sf)
library(terra)
library(ggplot2)
library(tidyterra)
library(lubridate)
library(dplyr)
library(tmap)
library(raster)
library(rnaturalearth)
library(jsonlite)
library(dplyr)
library(tools)
library(utils)
library(plotly)

```

```{Palisades fire stuff 1 r}

pal_csv <- read.csv("~/Local/Dissertation/ThomasFireYear_TIFFs/Palis_DailyMeanLuminosity.csv")


# Load satellite data
pal_outputs <- list.files("~/Local/Dissertation/Palis_TIFFs", full.names = TRUE)

# Load satellite data
pal_data <- lapply(pal_outputs, rast)

# Name the output rasters in satellite data based on the file names 
# Extract file names without extension and path
p.file_names <- tools::file_path_sans_ext(basename(pal_outputs))

# Name the list elements using extracted file names
names(pal_data) <- p.file_names

# Check the names
print(names(pal_data))

# Get rid of the ThomasFire_ prefix
names(pal_data) <- gsub("Palisades_", "", names(pal_data))

# Merge rasters with their corresponding metadata
p.combined_data <- lapply(names(pal_data), function(name) {
  list(
    raster = pal_data[[name]],
    metadata = pal_csv %>% filter(system.index == name)
  )
})

# Assign names to the combined list
names(p.combined_data) <- names(pal_data)

# Check merged structure
summary(p.combined_data)
plot(p.combined_data[[121]]$raster)

```


```{r Camp Fire Data}

# Load satellite data
camp_outputs <- list.files("~/Local/Dissertation/NTL_Wildfire_Recovery/CampFire_2_TIFFs", full.names = TRUE)

# Load in the camp fire csv
camp_csv <- read.csv("~/Local/Dissertation/NTl_Wildfire_Recovery/Camp_DailyMeanLuminosity.csv")

# Load satellite data
camp_data <- lapply(camp_outputs, rast)

# Name the output rasters in satellite data based on the file names 
# Extract file names without extension and path
c.file_names <- tools::file_path_sans_ext(basename(camp_outputs))

# Name the list elements using extracted file names
names(camp_data) <- c.file_names

# Check the names
print(names(camp_data))

# Get rid of the ThomasFire_ prefix
names(camp_data) <- gsub("Camp_", "", names(camp_data))

# Merge rasters with their corresponding metadata
c.combined_data <- lapply(names(camp_data), function(name) {
  list(
    raster = camp_data[[name]],
    metadata = camp_csv %>% filter(system.index == name)
  )
})

# Assign names to the combined list
names(c.combined_data) <- names(camp_data)

# Check merged structure
summary(c.combined_data)
plot(c.combined_data[[209]]$raster)

# print mean NTL after 2019-02-10 for the camp csv using Gap Filled 
mean_ntl_after <- mean(camp_csv$Gap_Filled_DNB_BRDF_Corrected_NTL[camp_csv$date > "2019-02-10"], na.rm = TRUE)


```
```{Thomas Fire Stuff 1 r}

# Filter data based on Mandatory_Quality_Flag condition
f.pal_csv <- pal_csv %>% 
  filter(Mandatory_Quality_Flag <= 0.05 | is.na(Mandatory_Quality_Flag))

# Convert date columns to Date type
f.pal_csv$date <- as.Date(f.pal_csv$date)

# Aggregate by week
f.pal_weekly <- f.pal_csv %>%
  mutate(week = floor_date(date, "week")) %>%
  group_by(week) %>%
  summarize(mean_NTL = mean(Gap_Filled_DNB_BRDF_Corrected_NTL, na.rm = TRUE))

# Plot the trendlines from both datasets
ggplot(f.pal_csv, aes(x = date, y = Gap_Filled_DNB_BRDF_Corrected_NTL)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Smooth Trend Line of NTL Data (Comparison)",
       x = "Date",
       y = "NTL Value") +
  theme_minimal() 


```

```{r}
# Cloud mask function
decode_cloud_mask <- function(val) {
  # Handle missing or NA
  if (is.na(val)) return(NA)
  
  # Convert to integer
  int_val <- as.integer(val)
  
  # Get bits (little endian)
  bits <- as.integer(intToBits(int_val))[1:2]  # Bits 0–1 only
  cloud_code <- paste0(rev(bits), collapse = "")  # Reversed for proper reading
  
  # Map bit pattern to label
  switch(cloud_code,
         "00" = "Confident Clear",
         "01" = "Probably Clear",
         "10" = "Probably Cloudy",
         "11" = "Cloudy",
         "Unknown")
}


```

```{r Camp Fire stuff 1}

# Filter data based on Mandatory_Quality_Flag condition
f.camp_csv <- camp_csv %>% 
  filter(Mandatory_Quality_Flag <= 0.05 | is.na(Mandatory_Quality_Flag))

# Convert date columns to Date type
f.camp_csv$date <- as.Date(f.camp_csv$date)

# Apply the decoding function to a new column
f.camp_csv <- f.camp_csv %>%
  mutate(Cloud_Quality = sapply(QF_Cloud_Mask, decode_cloud_mask))

# Aggregate by week
f.camp_weekly <- f.camp_csv %>%
  mutate(week = floor_date(date, "week")) %>%
  group_by(week) %>%
  summarize(mean_NTL = mean(Gap_Filled_DNB_BRDF_Corrected_NTL, na.rm = TRUE))


# Plot the trendlines from both datasets
ggplot(f.camp_weekly, aes(x = week, y = mean_NTL)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Weekly Average NTL in Camp Fire Data, Inclusive of Fire Weeks",
       x = "Date",
       y = "NTL Value") +
  theme_minimal() 


```

```{r Camp Fire plotted}

# Load in the camp fire csv
cbuff_csv <- read.csv("~/Local/Dissertation/NTL_Wildfire_Recovery/CBuff_DailyMeanLuminosity.csv")

# Filter data based on Mandatory_Quality_Flag condition
f.cbuff_csv <- cbuff_csv %>% 
  filter(Mandatory_Quality_Flag <= 0.05 | is.na(Mandatory_Quality_Flag))

# Convert date columns to Date type
f.cbuff_csv$date <- as.Date(f.cbuff_csv$date)

# Apply the decoding function to a new column
f.cbuff_csv <- f.cbuff_csv %>%
  mutate(Cloud_Quality = sapply(QF_Cloud_Mask, decode_cloud_mask))

# Aggregate by week
f.cbuff_weekly <- f.cbuff_csv %>%
  mutate(week = floor_date(date, "week")) %>%
  group_by(week) %>%
  summarize(mean_NTL = mean(Gap_Filled_DNB_BRDF_Corrected_NTL, na.rm = TRUE))


# Plot the trendlines from both datasets
ggplot(f.cbuff_weekly, aes(x = week, y = mean_NTL)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Weekly Average NTL in Buffer Data, Inclusive of Fire Weeks",
       x = "Date",
       y = "NTL Value") +
  theme_minimal() 

# Add source column to both datasets
f.camp_csv$source <- "Camp Fire"
f.cbuff_csv$source <- "Buffer"

# Add source column to both datasets
f.cbuff_weekly$source <- "Buffer"
f.camp_weekly$source <- "Camp Fire"


```

```{r}
#### Combine the two graphs 

# Combine the two dataframes
c.combined_csv <- bind_rows(f.cbuff_csv, f.camp_csv)
head(c.combined_csv)

# Combine the two dataframes
c.combined_weekly <- bind_rows(f.camp_weekly, f.cbuff_weekly)


# Plot the trendlines from both datasets
ggplot(c.combined_csv, aes(x = date, y = Gap_Filled_DNB_BRDF_Corrected_NTL, color = source, group = source)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Smooth Trend Line of NTL Data (Comparison)",
       x = "Date",
       y = "NTL Value") +
  scale_color_manual(values = c("blue4", "green4")) 

# Plot the trendlines from both datasets
ggplot(c.combined_weekly, aes(x = week, y = mean_NTL, color = source, group = source)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Smooth Trend Line of Mean NTL Data: Camp Fire and Buffer Data",
       x = "Date",
       y = "NTL Value") +
  scale_color_manual(values = c("blue4", "green4")) 

# Create an indicator for exclusion period
c.combined_weekly <- c.combined_weekly %>%
  filter(week < as.Date("2018-11-04") | week > as.Date("2019-02-10"))

# Plot: points for all data, smoothed lines only for non-excluded dates
ggplot(c.combined_weekly, aes(x = week, y = mean_NTL, color = source, group = source)) +
  geom_point() +
  geom_smooth(
    method = "loess", se = FALSE
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Broken Trend Line of NTL Data (Excluding Nov 4 – Feb 10)",
       x = "Date",
       y = "NTL Value") +
  scale_color_manual(values = c("blue4", "green4")) +
  scale_y_continuous(limits = c(0, 2.5)) 



```
```{r filtered plot}

# Create a plot that only shows trends from dates before November 8th
# Filter the data to only include dates before November 8th
f.camp_weeks_before <- c.combined_weekly %>%
  filter(week < as.Date("2018-11-04"))

# Plot the trendlines from both datasets

# On a day scale
f.camp_days_before <- c.combined_csv %>%
  filter(date < as.Date("2018-11-08"))

# Plot the trendlines from both datasets
ggplot(f.camp_days_before, aes(x = date, y = Gap_Filled_DNB_BRDF_Corrected_NTL, color = source, group = source)) +
  geom_point() +
   geom_smooth(method = "loess", se = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Comparison of Mean NTL Values Before Camp Fire",
       x = "Date",
       y = "NTL Value") +
  scale_color_manual(values = c("blue4", "green4")) 

# plot the days and weeks after the fire 
f.camp_days_after <- c.combined_csv %>%
  filter(date > as.Date("2019-02-10"))


# Plot the trendlines from both datasets
ggplot(f.camp_days_after, aes(x = date, y = Gap_Filled_DNB_BRDF_Corrected_NTL, color = source, group = source)) +
  geom_line() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Smooth Trend Line of NTL Data after Jan 07 (Comparison)",
       x = "Date",
       y = "NTL Value") +
  scale_color_manual(values = c("blue4", "green4"))


# plot the weeks after the fire
f.camp_weeks_after <- c.combined_weekly %>%
  filter(week > as.Date("2019-02-10"))

# Plot the trendlines from both datasets
ggplot(f.camp_weeks_after, aes(x = week, y = mean_NTL, color = source, group = source)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Smooth Trend Line of NTL Data after Jan 07 (Comparison)",
       x = "Date",
       y = "NTL Value") +
  scale_color_manual(values = c("blue4", "green4"))

#Print the mean NTL from the time period after the fire 
mean_ntl_after <- mean(f.camp_days_after$Gap_Filled_DNB_BRDF_Corrected_NTL, na.rm = TRUE)
mean_ntl_after
# Print the mean NTL from the time period before the fire
mean_ntl_before <- mean(f.camp_days_before$Gap_Filled_DNB_BRDF_Corrected_NTL, na.rm = TRUE)
```


```{r}
# make a difference in camp and buffer plot 

library(dplyr)
library(tidyr)
library(ggplot2)


ntl_diff_data <- c.combined_csv %>%
  select(date, source, Gap_Filled_DNB_BRDF_Corrected_NTL) %>%
  pivot_wider(names_from = source, values_from = Gap_Filled_DNB_BRDF_Corrected_NTL) %>%
  filter(!is.na(`Camp Fire`) & !is.na(Buffer)) %>%
  mutate(NTL_diff = `Camp Fire` - Buffer)

# Step 1: Compute the date gap to adjust post-fire dates
end_before <- max(ntl_diff_data$date[ntl_diff_data$date < as.Date("2018-11-08")])
start_after <- min(ntl_diff_data$date[ntl_diff_data$date >= as.Date("2019-02-10")])
gap <- as.numeric(start_after - end_before) - 1  # to close the visual gap


# Step 2: Adjust dates for visual continuity
f.before <- ntl_diff_data %>%
  filter(date < as.Date("2018-11-07")) %>%
  mutate(date_adjusted = date)

f.after <- ntl_diff_data %>%
  filter(date >= as.Date("2019-02-10")) %>%
  mutate(date_adjusted = date - gap)

f.all_adjusted <- bind_rows(f.before, f.after)

# Step 3: Add dashed line at visual break point
break_adjusted <- max(f.before$date_adjusted)

# Step 4: Plot
ggplot(f.all_adjusted, aes(x = date_adjusted, y = NTL_diff)) +
  geom_line(color = "lightgrey") +
  geom_vline(xintercept = as.numeric(break_adjusted), linetype = "dashed", color = "red") +
  annotate("text", x = break_adjusted + 2, y = max(f.all_adjusted$NTL_diff, na.rm = TRUE),
           label = "Camp Fire\nNov 8–Jan 7 excluded", color = "red", hjust = 0) +
  labs(
    title = "Difference in NTL (Camp - Buffer) Before and After Camp Fire",
    x = "Date (Adjusted)",
    y = "NTL Difference"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ntl_diff_f <- ntl_diff_data %>%
  filter(date < as.Date("2018-11-08"))

# Print the mean NTL_diff before the fire 
mean_ntl_diff <- mean(ntl_diff_f$NTL_diff, na.rm = TRUE)
mean_ntl_diff

# Print the mean NTL_diff after the fire
ntl_diff_a <- ntl_diff_data %>%
  filter(date >= as.Date("2019-02-10"))
mean_ntl_diff_after <- mean(ntl_diff_a$NTL_diff, na.rm = TRUE)
mean_ntl_diff_after



```



